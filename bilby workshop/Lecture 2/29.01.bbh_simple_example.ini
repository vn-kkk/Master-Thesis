# The accounting tag, onnly needed on LDG clusters.
# See https://ldas-gridmon.ligo.caltech.edu/accounting/condor_groups/determine_condor_account_group.html
# for help with determining what tag to use
accounting = FILL_THIS_IN
# Ignore the accounting tag when running locally or using SLUM.
# It is used on LIGO datagrid clusters to track what computing is spent. 
# Check out the website mentioned above to know what to fill in.


# A label to help us remember what the job was for
label = bbh_injection


# The directory to store results in
outdir = outdir_bbh_injection
# We can also give an absolute path for it to be created there.


# Which detectors to use, option: H1, L1, V1
detectors = [H1, L1]


# The duration of data to analyse in seconds
duration = 4
# Duration of data to analyse. In; general we use powers of two.
# Higher mass systems require lesser time and lower mass systems require more time.


# The sampler
sampler = dynesty


# The options to pass to the sampler
sampler-kwargs = {'nlive': 1000}
# To know what to put into sampler-kwargs we should look into the bilby source code itself.
# Eg: in the bilby git repos go to bilby > core > sampler > dynesty.py > other parameters under the class Dynesty 


# The prior file to use
prior-file = 29.01.bbh_simple_example.prior


# We want to inject a signal (in the case, drawn randomly from the prior)
injection = True


# We want to use Gaussian noise (default is to simulate it from O4-design sensitivity curves) 
gaussian-noise = True
# If we want a specific PSD look it up in bilby_pipe documentation and use that


# We'll do just one simulation
n-simulation = 1
# n-simulation is the number of simulations to run.


# We'll run one "parallel" job. This runs n-parallel *identical* jobs and then combines the results together into a single combined run
n-parallel = 1
# n-parallel runs those many number of identical jobs and combines them at the end.
# 4 jobs used for most publications. For cleaner results.


# Use parallisation using 4 cores on one node (remove comment to use)
request-cpus = 4
# This is the parallelization option for a given job. Each job will use these many number of CPUs. 
# It is basically n-parallel * request-cpus. If there is more than one simulation that will also get multiplied here.  
# This is enables only on dynesty, CPnest, PTMC.
# To check that this is working you will see this line in the logs: Setting up multiprocessing pool with 4 processes