{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilby_pipe and clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with bilby_pipe\n",
    "\n",
    "This tutorial will go through using `bilby_pipe`, a tool for running analyses\n",
    "at scale. `bilby_pipe` is not as flexible as `bilby`, but intended to do common\n",
    "tasks.\n",
    "\n",
    "All the files used are available in the repo [here](https://github.com/GregoryAshton/GWParameterEstimationWorkshop2020/tree/master/pipe_examples) for future reference.\n",
    "\n",
    "## Installation\n",
    "\n",
    "* `bilby_pipe` is intended for use on either HTCondor or slurm clusters. You\n",
    "can also use it on a local machine (running jobs serially). If you haven't\n",
    "already, follow the [installation steps](https://github.com/GregoryAshton/GWParameterEstimationWorkshop2020/blob/master/pages/installation.md) to make sure you have `bilby_pipe`\n",
    "installed.\n",
    "* To check it is installed, run\n",
    "```bash\n",
    "$ bilby_pipe --version\n",
    "bilby_pipe=1.0.0 (CLEAN) ....\n",
    "```\n",
    "\n",
    "## Dependencies required for remote data access\n",
    "* `bilby_pipe` uses the `gwpy`, `NDS2`, and `LDASTools-frameCPP` libraries to\n",
    "  access LIGO-Virgo-KAGRA data. To get full support, these need to be installed\n",
    "via conda\n",
    "```bash\n",
    "$ conda install -c conda-forge python-ldas-tools-framecpp python-nds2-client\n",
    "```\n",
    "If you don't install these, remote data access (i.e. not on a LIGO Data Grid\n",
    "cluster) will be difficult.\n",
    "\n",
    "## Basics\n",
    "\n",
    "`bilby_pipe` operates through an `ini` file (also known as a configuration file). The `ini` file specifies **what** to run and **how**. To see all the available options for the `ini` file, you can run\n",
    "\n",
    "```bash\n",
    "$ bilby_pipe --help\n",
    "```\n",
    "\n",
    "You can also view this output [in the docs](https://lscsoft.docs.ligo.org/bilby_pipe/master/user-interface.html#bilby-pipe-help).\n",
    "\n",
    "| :rocket: Task: run the `--help` command and check it produces output |\n",
    "| --- |\n",
    "\n",
    "## The ini file: simple BBH simulation\n",
    "\n",
    "An ini file consists of `key=value` pairs, a complete guide can be found [in the docs](https://lscsoft.docs.ligo.org/bilby_pipe/master/ini_file.html), here we will go through an example for a simulated signal.\n",
    "\n",
    "### Ini file example\n",
    "```\n",
    "# The accounting tag, onnly needed on LDG clusters.\n",
    "# See https://ldas-gridmon.ligo.caltech.edu/accounting/condor_groups/determine_condor_account_group.html\n",
    "# for help with determining what tag to use\n",
    "accounting = FILL_THIS_IN\n",
    "\n",
    "# A label to help us remember what the job was for\n",
    "label = bbh_injection\n",
    "\n",
    "# The directory to store results in\n",
    "outdir = outdir_bbh_injection\n",
    "\n",
    "# Which detectors to use, option: H1, L1, V1\n",
    "detectors = [H1, L1]\n",
    "\n",
    "# The duration of data to analyse in seconds\n",
    "duration = 4\n",
    "\n",
    "# The sampler\n",
    "sampler = dynesty\n",
    "\n",
    "# The options to pass to the sampler\n",
    "sampler-kwargs = {'nlive': 1000}\n",
    "\n",
    "# The prior file to use\n",
    "prior-file = bbh_simple_example.prior\n",
    "\n",
    "# We want to inject a signal (in the case, drawn randomly from the prior)\n",
    "injection = True\n",
    "\n",
    "# We want to use Gaussian noise (default is to simulate it from O4-design sensitivity curves) \n",
    "gaussian-noise = True\n",
    "\n",
    "# We'll do just one simulation\n",
    "n-simulation = 1\n",
    "\n",
    "# We'll run one \"parallel\" job. This runs n-parallel *identical* jobs and then combines the results together into a single combined run\n",
    "n-parallel = 1\n",
    "\n",
    "# Use parallisation using 4 cores on one node (remove comment to use)\n",
    "# request-cpus = 4\n",
    "\n",
    "```\n",
    "| :rocket: Task: save the contents of the ini file above in a file `bbh_simple_example.ini` |\n",
    "| --- |\n",
    "\n",
    "### Parallelisation\n",
    "As mentioned elsewhere, bilby supports a paralleisation up to the number of cores available a node. To access this, add the line\n",
    "```\n",
    "request-cpus = 4\n",
    "```\n",
    "You can check this is being applied by seeing this line in the logs:\n",
    "```\n",
    "Setting up multiproccesing pool with 4 processes.\n",
    "```\n",
    "\n",
    "### Prior file\n",
    "Note, in the ini file, we specified `prior-file = bbh_simple_example.prior`, this is pointing to a file (you can specify and absolute or relative path as needed).\n",
    "Here are the contents of that file, as you can see, this is a simple prior in only the distance and inclination\n",
    "```\n",
    "mass_1 = 50.0\n",
    "mass_2 = 45.0\n",
    "a_1 = 0.0\n",
    "a_2 = 0.0\n",
    "tilt_1 = 0.0\n",
    "tilt_2 = 0.0\n",
    "phi_12 = 0.0\n",
    "phi_jl = 0.0\n",
    "luminosity_distance =  bilby.gw.prior.UniformComovingVolume(name='luminosity_distance', minimum=1e2, maximum=5e3, unit='Mpc')\n",
    "dec = -0.2\n",
    "ra = 1.4\n",
    "theta_jn = Sine(name='theta_jn')\n",
    "psi = 0.0\n",
    "phase = 0.0\n",
    "geocent_time = 0.0\n",
    "```\n",
    "\n",
    "| :rocket: Task: save the contents of the ini file above in a file `bbh_simple_example.prior`. |\n",
    "| --- |\n",
    "\n",
    "### Ini file inputs\n",
    "In the example above, we see a few different styles of input, let's briefly review them\n",
    "* `key = value` (e.g, `sampler = dynesty`, `duration=4`, etc)\n",
    "* `key = list` (e.g. `detectors = [H1, L1]`\n",
    "* `key = dict` (e.g. `sampler-kwargs = {'nlive': 1000}`) note that the dictionary itself can handle lots of types of input.\n",
    "* `key = boolean` (.e.g `gaussian-noise = True`)\n",
    "\n",
    "### Running the example\n",
    "\n",
    "If you followed the steps above, you should have two files stored `bbh_simple_example.ini` and `bilby_simple_example.prior`. If you do, you can run run bilby_pipe with the command\n",
    "\n",
    "```bash\n",
    "$ bilby_pipe bbh_simple_example.ini\n",
    "```\n",
    "This will produce the following output:\n",
    "```\n",
    "09:37 bilby_pipe INFO    : Running bilby_pipe version: 1.0.0: (CLEAN) e6223de 2020-07-27 17:01:09 -0500\n",
    "09:37 bilby_pipe INFO    : Running bilby: 1.0.0: release\n",
    "09:37 bilby_pipe INFO    : Setting segment duration 4.0s\n",
    "09:37 bilby_pipe INFO    : Setting prior-file to bbh_simple_example.prior\n",
    "09:37 bilby_pipe INFO    : Setting n_simulation=1\n",
    "09:37 bilby_pipe INFO    : Using injection file outdir_bbh_injection/data/bbh_injection_injection_file.dat\n",
    "09:37 bilby_pipe INFO    : Setting analysis request_memory=4.0GB\n",
    "09:37 bilby_pipe INFO    : Setting request_memory_generation=8GB\n",
    "09:37 bilby_pipe INFO    : Setting analysis request_cpus = 1\n",
    "09:37 bilby_pipe INFO    : Using geocent_time prior from prior_file\n",
    "09:37 bilby_pipe INFO    : Input prior = {\n",
    "  \"mass_1\": \"DeltaFunction(peak=50.0, name=None, latex_label=None, unit=None)\",\n",
    "  \"mass_2\": \"DeltaFunction(peak=45.0, name=None, latex_label=None, unit=None)\",\n",
    "  \"a_1\": \"DeltaFunction(peak=0.0, name=None, latex_label=None, unit=None)\",\n",
    "  \"a_2\": \"DeltaFunction(peak=0.0, name=None, latex_label=None, unit=None)\",\n",
    "  \"tilt_1\": \"DeltaFunction(peak=0.0, name=None, latex_label=None, unit=None)\",\n",
    "  \"tilt_2\": \"DeltaFunction(peak=0.0, name=None, latex_label=None, unit=None)\",\n",
    "  \"phi_12\": \"DeltaFunction(peak=0.0, name=None, latex_label=None, unit=None)\",\n",
    "  \"phi_jl\": \"DeltaFunction(peak=0.0, name=None, latex_label=None, unit=None)\",\n",
    "  \"luminosity_distance\": \"UniformComovingVolume(minimum=100.0, maximum=5000.0, cosmology=FlatLambdaCDM(name=\\\"Planck15\\\", H0=67.7 km / (Mpc s), Om0=0.307, Tcmb0=2.725 K, Neff=3.05, m_nu=[0.   0.   0.06] eV, Ob0=0.0486), name='luminosity_distance', latex_label='$d_L$', unit=Unit(\\\"Mpc\\\"), boundary=None)\",\n",
    "  \"dec\": \"DeltaFunction(peak=-0.2, name=None, latex_label=None, unit=None)\",\n",
    "  \"ra\": \"DeltaFunction(peak=1.4, name=None, latex_label=None, unit=None)\",\n",
    "  \"theta_jn\": \"Sine(name='theta_jn', latex_label='$\\\\\\\\theta_{JN}$', unit=None, minimum=0, maximum=3.141592653589793, boundary=None)\",\n",
    "  \"psi\": \"DeltaFunction(peak=0.0, name=None, latex_label=None, unit=None)\",\n",
    "  \"phase\": \"DeltaFunction(peak=0.0, name=None, latex_label=None, unit=None)\",\n",
    "  \"geocent_time\": \"DeltaFunction(peak=0.0, name=None, latex_label=None, unit=None)\"\n",
    "}\n",
    "09:37 bilby_pipe WARNING : File outdir_bbh_injection/bbh_injection_config_complete.ini already exists, not writing to file.\n",
    "09:37 bilby_pipe INFO    : Setting segment duration 4.0s\n",
    "09:37 bilby_pipe INFO    : Setting prior-file to /home/user1/GWParameterEstimationWorkshop2020/pipe_examples/bbh_simple_example.prior\n",
    "09:37 bilby_pipe INFO    : Setting n_simulation=1\n",
    "09:37 bilby_pipe INFO    : Using injection file outdir_bbh_injection/data/bbh_injection_injection_file.dat\n",
    "09:37 bilby_pipe INFO    : Setting analysis request_memory=4.0GB\n",
    "09:37 bilby_pipe INFO    : Setting request_memory_generation=8GB\n",
    "09:37 bilby_pipe INFO    : Setting analysis request_cpus = 1\n",
    "09:37 bilby_pipe INFO    : Setting segment trigger-times [0]\n",
    "09:37 bilby_pipe INFO    : DAG generation complete, to submit jobs run:\n",
    "  $ condor_submit_dag outdir_bbh_injection/submit/dag_bbh_injection.submit\n",
    "09:37 bilby_pipe INFO    : Using geocent_time prior from prior_file\n",
    "09:37 bilby_pipe INFO    : Overview page available at outdir_bbh_injection/results_page/overview.html\n",
    "```\n",
    "| :rocket: Task: run  `bilby_pipe bbh_simple_example.ini` and confirm you get output like that above |\n",
    "| --- |\n",
    "\n",
    "Note, this has **not** run or submitted the job, only created the files neccersery to do so. You should now see a directory `outdir_bbh_injection` with several sub-directories:\n",
    "```bash\n",
    "$ ls outdir_bbh_injection/\n",
    "data  log_data_analysis  log_data_generation  log_results_page  result  results_page  submit  bbh_injection_config_complete.ini\n",
    "```\n",
    "Except the `submit` directory, these will be empty right now and populated one the run starts. Let's look in the `submit` directory\n",
    "```bash\n",
    "$ ls outdir_bbh_injection/submit/\n",
    "bash_bbh_injection.sh  # <- This is a bash file containing all the commands to run different parts of the job locally\n",
    "bbh_injection_data0_0_analysis_H1L1_dynesty.submit  # <- This is a HTCondor submit file for the analysis step\n",
    "bbh_injection_data0_0_generation.submit  # <- This is a HTCondor submit file for the analysis step\n",
    "dag_bbh_injection.submit  # <- This is the HTCondor dag submit file\n",
    "```\n",
    "\n",
    "### Submitting the job: HTCondor\n",
    "If you are running things on a HTCondor cluster, you can now submit the job with\n",
    "```bash\n",
    "$ condor_submit_dag outdir_bbh_injection/submit/dag_bbh_injection.submit\n",
    "```\n",
    "Alternatively, you can submit things when you run `bilby_pipe` by adding the `--submit` flag, i.e.\n",
    "```bash\n",
    "$ bilby_pipe bbh_simple_example.ini --submit\n",
    "```\n",
    "\n",
    "### Submitting the job: Slurm\n",
    "As you'll notice, the **default** in bilby pipe is to use the `HTCondor` scheduler (this is the standard on all LDG clusters). If you are on a Slurm cluster, you need to **add** some lines to the ini file, a detailed discussion of these can be found [in the documentation](https://lscsoft.docs.ligo.org/bilby_pipe/1.0.1/user-interface.html#using-the-slurm-batch-scheduler), but will depend on your cluster setup.\n",
    "\n",
    "### Submitting the job: local\n",
    "All bilby_pipe jobs can be run on your local machine. There are two ways to do this\n",
    "#### 1. Using the `--local` flag\n",
    "You can run \n",
    "```\n",
    "$ bilby_pipe bbh_simple_example.ini --local\n",
    "```\n",
    "This will run each step of the job sequentially on your local machine\n",
    "#### 2. Using the bash file\n",
    "Let's look inside the `bash` file\n",
    "```bash\n",
    "$ cat outdir_bbh_injection/submit/bash_bbh_injection.sh \n",
    "#!/usr/bin/env bash\n",
    "\n",
    "# bbh_injection_data0_0_generation\n",
    "# PARENTS \n",
    "# CHILDREN bbh_injection_data0_0_analysis_H1L1_dynesty\n",
    "/home/user1/anaconda3/envs/bilby/bin/bilby_pipe_generation outdir_bbh_injection/bbh_injection_config_complete.ini --label bbh_injection_data0_0_generation --idx 0 --trigger-time 0 --injection-file outdir_bbh_injection/data/bbh_injection_injection_file.dat\n",
    "\n",
    "# bbh_injection_data0_0_analysis_H1L1_dynesty\n",
    "# PARENTS bbh_injection_data0_0_generation\n",
    "# CHILDREN \n",
    "/home/user1/anaconda3/envs/bilby/bin/bilby_pipe_analysis outdir_bbh_injection/bbh_injection_config_complete.ini --outdir outdir_bbh_injection --detectors H1 --detectors L1 --label bbh_injection_data0_0_analysis_H1L1_dynesty --data-dump-file outdir_bbh_injection/data/bbh_injection_data0_0_generation_data_dump.pickle --sampler dynesty\n",
    "```\n",
    "This contains the set of instructions to run each step of the job. You can run this directly, i.e. with\n",
    "```bash\n",
    "$ bash outdir_bbh_injection/submit/bash_bbh_injection.sh\n",
    "```\n",
    "Or you can copy parts of the file you want to run to a separate script and run each one individually (this is often very useful if you **just** want to run a step locally, i.e. the plotting).\n",
    "| :rocket: Task: the example script using *either* the `--local` flag or the bash file |\n",
    "| --- |\n",
    "\n",
    "### Looking at the outputs\n",
    "Once you have run the example to completion, we should check the outputs. If you ran using either `slurm` or `HTCondor` the `log*` files will be populated with files containing the run outputs. If instead you ran it locally, this output would have been printed to the terminal.\n",
    "\n",
    "#### The dynesty output\n",
    "If you are using the dynesty sampler, you'll get output like this (either in the logs, or printed to the terminal)\n",
    "```\n",
    "136it [00:04,  4.57it/s, bound:0 nc:  1 ncall:6.6e+02 eff:20.7% logz-ratio=146.11+/-0.13 dlogz:321.891>0.1]\n",
    "151it [00:04,  6.44it/s, bound:0 nc:  3 ncall:6.8e+02 eff:22.3% logz-ratio=151.24+/-0.13 dlogz:316.951>0.1]\n",
    "169it [00:04,  9.05it/s, bound:0 nc:  1 ncall:7.0e+02 eff:24.1% logz-ratio=155.53+/-0.13 dlogz:312.568>0.1]\n",
    "185it [00:04, 12.54it/s, bound:0 nc:  1 ncall:7.3e+02 eff:25.3% logz-ratio=160.67+/-0.14 dlogz:307.518>0.1]\n",
    "203it [00:04, 17.38it/s, bound:0 nc:  1 ncall:7.5e+02 eff:27.0% logz-ratio=168.88+/-0.14 dlogz:299.232>0.1]\n",
    "```\n",
    "By column, this tells you: \n",
    "* `203it`: the number of iterations\n",
    "* `00:04`: the time taken so far (note if jobs are restarted this counter is reset to zero)\n",
    "* `17.38it/s`: the number of iterations per second\n",
    "* `bound:0`: the bound index (see [dynesty docs](https://dynesty.readthedocs.io/en/latest/faq.html))\n",
    "* `nc:  1`: the number of likelihood calls used in the last iterations\n",
    "* `ncall:7.5e+02`: the total number of calls\n",
    "* `eff:27.0%`: the sampling efficiency \n",
    "* `logz-ratio=168.88+/-0.14`: the current logz-ratio estimate (if > 0, this is a Bayes factor in support of the signal hypothesis vs. Gaussian noise)\n",
    "* `dlogz:299.232>3` the estimated remaining evidence and threshold (in this instance, 0.1). Sampling will finish when `dlogz` is less than the threshold.\n",
    "\n",
    "Roughly speaking `logz-ratio + dlogz` is an estimate of the final evidence, but note that `dlogz` can jump if new regions of the parameter space are found with high likelihoods.\n",
    "\n",
    "#### Output files\n",
    "In the `results` directory, we have all of the relevant output:\n",
    "```bash\n",
    "$ ls outdir_bbh_injection/result\n",
    "bbh_injection_data0_0_analysis_H1L1_dynesty_result.json  # <- THIS IS THE MAIN RESULT FILE\n",
    "bbh_injection_data0_0_analysis_H1L1_dynesty_dynesty.pickle  # <- A python pickle file of the dynesty sampler output\n",
    "bbh_injection_data0_0_analysis_H1L1_dynesty_resume.pickle  # <- A python pickle file used to store results during the run\n",
    "bbh_injection_data0_0_analysis_H1L1_dynesty_samples.dat  # <- A set of samples created during the run, not the final output\n",
    "bbh_injection_data0_0_analysis_H1L1_dynesty_checkpoint_run.png \n",
    "bbh_injection_data0_0_analysis_H1L1_dynesty_checkpoint_stats.png\n",
    "bbh_injection_data0_0_analysis_H1L1_dynesty_checkpoint_trace.png\n",
    "```\n",
    "The last three `png` images contain diagnostic plots. These will be updated during the run and help show the progress\n",
    "\n",
    "#### The run plot\n",
    "Shows the [dynesty summary plot](https://dynesty.readthedocs.io/en/latest/quickstart.html#summary-plots)\n",
    "![run](example_outputs/bbh_injection_data0_0_analysis_H1L1_dynesty_checkpoint_run.png)\n",
    "\n",
    "#### The stats plot\n",
    "This is a plot of the number of calls and the scale parameter for nested sampling proposals (for this short run, it is a little uninteresting)\n",
    "![stats](example_outputs/bbh_injection_data0_0_analysis_H1L1_dynesty_checkpoint_stats.png)\n",
    "\n",
    "#### The trace plot\n",
    "Shows the [dynesty trace plot](https://dynesty.readthedocs.io/en/latest/quickstart.html#trace-plots). The right-hand side are the 1D posteriors\n",
    "![stats](example_outputs/bbh_injection_data0_0_analysis_H1L1_dynesty_checkpoint_trace.png)\n",
    "\n",
    "## Priors\n",
    "\n",
    "As seen above, you can specify your own prior using a prior file. `bilby_pipe` also provides a set of default prior files based on the duration of data. These are:\n",
    "* [4s](https://git.ligo.org/lscsoft/bilby_pipe/-/blob/master/bilby_pipe/data_files/4s.prior)\n",
    "* [8s](https://git.ligo.org/lscsoft/bilby_pipe/-/blob/master/bilby_pipe/data_files/8s.prior)\n",
    "* [16s](https://git.ligo.org/lscsoft/bilby_pipe/-/blob/master/bilby_pipe/data_files/16s.prior)\n",
    "* [32s](https://git.ligo.org/lscsoft/bilby_pipe/-/blob/master/bilby_pipe/data_files/32s.prior)\n",
    "* [64s](https://git.ligo.org/lscsoft/bilby_pipe/-/blob/master/bilby_pipe/data_files/64s.prior)\n",
    "* [128s](https://git.ligo.org/lscsoft/bilby_pipe/-/blob/master/bilby_pipe/data_files/128s.prior)\n",
    "\n",
    "The chirp-mass range ensures that the signals fit within the data duration. To use these default priors, simplify specify\n",
    "```\n",
    "prior-file=4s\n",
    "```\n",
    "\n",
    "## Accessing data\n",
    "\n",
    "If you want to access data, you'll need to specify a `trigger-time` (a GPS time as used by LIGO/Virgo) and the `channel-dict` used to determine *which* data to use. Here is an example ini file for running on GW150914\n",
    "```\n",
    "# The accounting tag, onnly needed on LDG clusters.\n",
    "# See https://ldas-gridmon.ligo.caltech.edu/accounting/condor_groups/determine_condor_account_group.html\n",
    "# for help with determining what tag to use\n",
    "accounting = FILL_THIS_IN\n",
    "\n",
    "# A label to help us remember what the job was for\n",
    "label = GW150914\n",
    "\n",
    "# The directory to store results in\n",
    "outdir = outdir_bbh_gwosc_GW150914\n",
    "\n",
    "# Which detectors to use, option: H1, L1, V1\n",
    "detectors = [H1, L1]\n",
    "\n",
    "# The duration of data to analyse in seconds\n",
    "duration = 4\n",
    "\n",
    "# The sampler\n",
    "sampler = dynesty\n",
    "\n",
    "# The options to pass to the sampler\n",
    "sampler-kwargs = {'nlive': 1000}\n",
    "\n",
    "# The prior file to use\n",
    "prior-file = 4s\n",
    "\n",
    "# For events, we can pull in the time using a string\n",
    "trigger-time = GW150914\n",
    "\n",
    "# You could alternatively do (uncomment to test)\n",
    "# trigger-time = 1126259462.4\n",
    "\n",
    "# Here we specify the GWOSC channel, if you want to use a different channel\n",
    "# you can pass that per-detector\n",
    "channel-dict = {H1:GWOSC, L1:GWOSC}\n",
    "```\n",
    "\n",
    ":warning: Warning: running the ini file above will take ~ 12hrs as it is a full analysis of GW150914\n",
    "\n",
    "## Inject a signal into real data\n",
    "\n",
    "```\n",
    "# The accounting tag, onnly needed on LDG clusters.\n",
    "# See https://ldas-gridmon.ligo.caltech.edu/accounting/condor_groups/determine_condor_account_group.html\n",
    "# for help with determining what tag to use\n",
    "accounting = FILL_THIS_IN\n",
    "\n",
    "# A label to help us remember what the job was for\n",
    "label = gwosc_injection\n",
    "\n",
    "# The directory to store results in\n",
    "outdir = outdir_bbh_gwosc_injection\n",
    "\n",
    "# Which detectors to use, option: H1, L1, V1\n",
    "detectors = [H1, L1]\n",
    "\n",
    "# The duration of data to analyse in seconds\n",
    "duration = 4\n",
    "\n",
    "# The sampler\n",
    "sampler = dynesty\n",
    "\n",
    "# The options to pass to the sampler\n",
    "sampler-kwargs = {'nlive': 1000}\n",
    "\n",
    "# The prior file to use\n",
    "prior-file = 4s\n",
    "\n",
    "# Specify a random time (a few hundred seconds after GW150914)\n",
    "trigger-time = 1126259600\n",
    "\n",
    "# Here we specify the GWOSC channel, if you want to use a different channel\n",
    "# you can pass that per-detector\n",
    "channel-dict = {H1:GWOSC, L1:GWOSC}\n",
    "\n",
    "injection=True\n",
    "injection-dict={'chirp_mass': 17.051544979894693, 'mass_ratio': 0.3183945489993522, 'a_1': 0.29526500202350264, 'a_2': 0.23262056301313416, 'tilt_1': 1.0264673717225983, 'tilt_2': 2.1701305583885513, 'phi_12': 5.0962562029664955, 'phi_jl': 2.518241237045709, 'luminosity_distance': 497.2983560174788, 'dec': 0.2205292600865073, 'ra': 3.952677097361719, 'theta_jn': 1.8795187965094322, 'psi': 2.6973435044499543, 'phase': 3.686990398567503, 'geocent_time': 1126259600}\n",
    "```\n",
    "\n",
    ":warning: take care to make sure the `geocent_time` of the injection falls within the prior window (+/- 0.2 around the `trigger_time`)\n",
    "\n",
    "Running this, you can check estimated SNR of the injected signal in the logs, e.g.\n",
    "\n",
    "```\n",
    "12:53 bilby INFO    : Injected signal in L1:\n",
    "12:53 bilby INFO    :   optimal SNR = 13.28\n",
    "12:53 bilby INFO    :   matched filter SNR = -3.65+38.02j\n",
    "```\n",
    "\n",
    ":warning: Warning: running the ini file above will take ~ 12hrs as it is a full analysis of GW150914\n",
    "\n",
    "## Power Spectral Densities\n",
    "\n",
    "### Setting the PSD using a file\n",
    "```\n",
    "psd-dict PSD_DICT   Dictionary of PSD files to use (default: None)\n",
    "```\n",
    "e.g.\n",
    "```\n",
    "psd-dict = {H1:psds_files/h1.psd}\n",
    "```\n",
    "\n",
    "### Estimating the PSD from the data\n",
    "If no PSD is given, one will be estimated from the data. Note this differs to standard LVK analyses which use a BayesWave generated PSD. Here are the options to control how that PSD is estimated.\n",
    "```\n",
    "  --psd-fractional-overlap PSD_FRACTIONAL_OVERLAP\n",
    "                        Fractional overlap of segments used in estimating the\n",
    "                        PSD (default: 0.5)\n",
    "  --post-trigger-duration POST_TRIGGER_DURATION\n",
    "                        Time (in s) after the trigger_time to the end of the\n",
    "                        segment (default: 2.0)\n",
    "  --sampling-frequency SAMPLING_FREQUENCY\n",
    "  --psd-length PSD_LENGTH\n",
    "                        Sets the psd duration (up to the psd-duration-\n",
    "                        maximum). PSD duration calculated by psd-length x\n",
    "                        duration [s]. Default is 32. (default: 32)\n",
    "  --psd-maximum-duration PSD_MAXIMUM_DURATION\n",
    "                        The maximum allowed PSD duration in seconds, default\n",
    "                        is 1024s. (default: 1024)\n",
    "  --psd-method PSD_METHOD\n",
    "                        PSD method see gwpy.timeseries.TimeSeries.psd for\n",
    "                        options (default: median)\n",
    "  --psd-start-time PSD_START_TIME\n",
    "                        Start time of data (relative to the segment start)\n",
    "                        used to generate the PSD. Defaults to psd-duration\n",
    "                        before the segment start time (default: None)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
