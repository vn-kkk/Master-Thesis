# JOB SUBMISSION ARGUMENTS
# ------------------------

	# The accounting tag, only needed on LDG clusters.
	# See https://ldas-gridmon.ligo.caltech.edu/accounting/condor_groups/determine_condor_account_group.html
	# for help with determining what tag to use
accounting = FILL_THIS_IN
	# Ignore the accounting tag when running locally or using SLUM.
	# It is used on LIGO datagrid clusters to track what computing is spent. 
	# Check out the website mentioned above to know what to fill in.

	# A label to help us remember what the job was for
label = relative_binning_BNS_cluster

	# The directory to store results in
outdir = outdir_relative_binning_BNS_cluster
	# We can also give an absolute path for it to be created there.

	# Use parallisation using 4 cores on one node 
request-cpus = 32
	# This is the parallelization option for a given job. Each job will use these many number of CPUs. 
	# It is basically n-parallel * request-cpus. If there is more than one simulation that will also get multiplied here.  
	# This is enabled only on dynesty, CPnest, PTMC.
	# To check that this is working you will see this line in the logs: Setting up multiprocessing pool with 4 processes

	# setting up the scheduler 
scheduler = slurm
 
	# activating the environment
scheduler-env = bilby

	# which partitions to use.
scheduler-args = partition=all



# INJECTION ARGUMENTS
# -------------------

	# We want to inject a signal (in this case, drawn randomly from the prior)
injection = True
	# We can also create a specific injection file or dictonary that we want to put in.

	# Set the above to false when using this
	# A single injection dictionary given in the ini file
injection-dict = {'fiducial': 1, 'mass_1': 1.5, 'mass_2': 1.3, 'chi_1': 0.02, 'chi_2':0.02, 'lambda_1': 545.0, 'lambda_2': 1346.0, 'luminosity_distance': 2000.0, 'theta_jn': 0.4, 'psi': 2.659, 'phase':1.3, 'geocent_time': 1126259642.413, 'ra': 1.375, 'dec': -1.2108}


# DATA GENERATION ARGUMENTS
# -------------------------

	# We want to use Gaussian noise (default is to simulate it from O4-design sensitivity curves) 
gaussian-noise = True
	# If we want a specific PSD look it up in bilby_pipe documentation and use that

	# We'll do just one simulation
n-simulation = 1
	# n-simulation is the number of simulations to run.



# WAVWFORM ARGUMENTS
# -----------------

waveform-approximant = IMRPhenomPv2_NRTidal

reference-frequency = 50.0

	# Equivalent to waveform_arguments in the code
waveform-arguments-dict = {'minimum_frequency': 75.0}
	# A dictionary of arbitrary additional waveform-arguments to pass to the bilby waveform generatorâ€™s waveform_arguments


waveform-generator = bilby.gw.WaveformGenerator

frequency-domain-source-model = lal_binary_neutron_star_relative_binning

conversion-function = bilby.gw.conversion.convert_to_lal_binary_neutron_star_parameters



# DETECTOR ARGUMENTS
# ------------------

	# Which detectors to use, option: H1, L1, V1, K1 
detectors = [H1, L1, V1]

minimum-frequency = 75.0

	# The duration of data to analyse in seconds
duration = 32.0
	# Duration of data to analyse. In general we use powers of two.
	# Higher mass systems(BBH) require lesser time and lower mass systems(BNS) require more time.

sampling-frequency = 4096

generation-seed = 88170235



# PRIOR ARGUMENTS
# ---------------

# default-prior = BBHPriorDict

	# The prior file to use
prior-file = relative_binning_BNS_cluster.prior



# LIKELIHOOD ARGUMENTS
# --------------------

likelihood-type = RelativeBinningGravitationalWaveTransient

fiducial-parameters ={'fiducial': 1, 'chirp_mass': 1.2150360414642816, 'symmetric_mass_ratio': 0.24872448979591844,'chi_1': 0.02, 'chi_2':0.02, 'lambda_1': 545.0, 'lambda_2': 1346.0, 'luminosity_distance': 2000.0, 'theta_jn': 0.4, 'psi': 2.659, 'phase':1.3, 'geocent_time': 1126259642.413, 'ra': 1.375, 'dec': -1.2108} 
	# The reference parameters for the relative binning likelihod. 
	# If this is not specified, the value will be drawn from the prior.



# SAMPLER ARGUMENTS
# -----------------

sampler = dynesty

	# The options to pass to the sampler
sampler-kwargs = {'nlive': 1000, 'plot': True}
	# To know what to put into sampler-kwargs we should look into the bilby source code itself.
	# Eg: in the bilby git repos go to bilby > core > sampler > dynesty.py > other parameters under the class Dynesty 

	# We'll run one "parallel" job. 
	# This runs n-parallel *identical* jobs and then combines the results together into a single combined run
n-parallel = 1
	# n-parallel runs those many number of identical jobs and combines them at the end.
	# 4 jobs used for most publications. For cleaner results during production runs.

reweight-nested-samples = True
	# Whether to reweight nested samples directly. Currently this only works with dynesty. 