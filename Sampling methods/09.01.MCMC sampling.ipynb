{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "Sampling from a distribution\n",
    "</h1>\n",
    "There is a target distribution $p($x$)$. Most of the times we don't know this target distribution. But we do know the numerator which is $f(x)$. \n",
    "\n",
    "The probability density function is given by:\n",
    "\n",
    "$p(x)=\\frac{f(x)}{Normalizing\\ constant}$\n",
    "where, $f(x)$ is a piecewize function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The numerator of the target distribution\n",
    "def f(x):\n",
    "    if x>=1:\n",
    "        return np.exp(-(x-1)/2) + np.exp(-(x-1)**2)\n",
    "    else:\n",
    "        return np.exp((x-1)/3) + np.exp((x-1)**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal PDF which is the candidate distribution. mu is the mean and sigma the standard deviation\n",
    "def g(x, mu, sigma):\n",
    "    return 1/(sigma*np.sqrt(2*np.pi)) * np.exp(-0.5*((x-mu)/sigma)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawing the target distribution $p(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_const=7.16556 # found using wolfram alpha\n",
    "\n",
    "x_vals = np.arange(-5, 15,.1)\n",
    "f_vals = [f(x) for x in x_vals]\n",
    "p_vals = [f/norm_const for f in f_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the two functions\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x_vals, f_vals)\n",
    "plt.plot(x_vals, p_vals)\n",
    "plt.title('PDFs',fontsize=15)\n",
    "plt.legend(['f(x): Numerator of the target distribution', 'p(x): The target distribution'])\n",
    "plt.xlabel('x',fontsize=15)\n",
    "plt.ylabel('p(x) and f(x)',fontsize=15)\n",
    "plt.axvline(1, color='g', linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True expected value for a random draw from p(x). We will use this as a control to see how well the other methods work\n",
    "true_exp = 1.94709 / norm_const # from wolframalpha\n",
    "print(true_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:cyan\">\n",
    "Accept-Reject (Rejection) Sampling \n",
    "</h1>\n",
    "\n",
    "Accepting ptobability is given by:\n",
    "$\\frac{f(s)}{M*g(s)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:cyan\">\n",
    "with Normal (0,3) candidate distriution\n",
    "</h3>\n",
    "\n",
    "0 is the mean. That is where the distibution in centered at.\\\n",
    "3 is its standard deviation. Higher value causes the tail to widen out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.arange(-30,30,.1)\n",
    "f_vals = [f(x) for x in x_vals]\n",
    "g_vals = g(x_vals, 0, 3) # the candidate distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$M$ the 'stretch factor' is chosen such that $M*g(x)$ lies above $f(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=1\n",
    "\n",
    "# Plot the two functions\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x_vals, f_vals)\n",
    "plt.plot(x_vals, M*g_vals)\n",
    "plt.title(\"M=%s\"%M, fontsize=15)\n",
    "plt.legend(['f(x)', 'M*g(x)'])\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('Density', fontsize=15)\n",
    "plt.axvline(1, color='b', linestyle='--')\n",
    "plt.axvline(0, color='r', linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$M*g(x)$ is not over $f(x)$ for $M=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=10\n",
    "\n",
    "# Plot the two functions\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x_vals, f_vals)\n",
    "plt.plot(x_vals, M*g_vals)\n",
    "plt.title(\"M=%s\"%M, fontsize=15)\n",
    "plt.legend(['f(x)', 'M*g(x)'])\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('Density', fontsize=15)\n",
    "plt.axvline(1, color='b', linestyle='--')\n",
    "plt.axvline(0, color='r', linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$M*g(x)$ is still not over $f(x)$ for $M=10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=1000\n",
    "\n",
    "# Plot the two functions\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x_vals, f_vals)\n",
    "plt.plot(x_vals, M*g_vals)\n",
    "plt.title(\"M=%s\"%M, fontsize=15)\n",
    "plt.legend(['f(x)', 'M*g(x)'])\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('Density', fontsize=15)\n",
    "plt.axvline(1, color='b', linestyle='--')\n",
    "plt.axvline(0, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$M*g(x)$ is way over $f(x)$ for $M=1000$. We migh think this is overkill because $M*g(x)$ is way above $f(x)$ but under closer inspection we see... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 1000\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(x_vals, f_vals)\n",
    "plt.plot(x_vals, M*g_vals)\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('Density', fontsize=15)\n",
    "plt.legend(['f(x)', 'Mg(x)'])\n",
    "\n",
    "plt.title(\"M=%s\"%M, fontsize=15)\n",
    "plt.axvline(1, color='b', linestyle='--')\n",
    "plt.axvline(0, color='r', linestyle='--')\n",
    "\n",
    "plt.ylim(0,.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...some values of $f(x)$ are still not under $M*g(x)$. Still since this region is small it is good enough to be used for sampling. So we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all accepted samples here\n",
    "samples=[]\n",
    "\n",
    "# try these many candidates\n",
    "N=1000000\n",
    "\n",
    "for _ in  range (N):\n",
    "    # sample a candidate\n",
    "    candidate = np.random.normal(0,3) # 0 is the mean and 3 is the SD\n",
    "\n",
    "    # calculate probability of accepting this candidate\n",
    "    prob_accept = f(candidate) / (M*g(candidate, 0 ,3))\n",
    "\n",
    "    # accept with calculated probability\n",
    "    if np.random.random() < prob_accept:\n",
    "        samples.append(candidate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Samples Collected: %s\"%len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Efficiency: %s\"%round(len(samples) / N, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get very few samples and the accuracy of $0.7%$ is not very good. This is because $M$ is huge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(samples, bins=200, density=True)\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('Density', fontsize=15)\n",
    "plt.plot(x_vals, [f/norm_const for f in f_vals], linewidth=2) # [p(x)] i.e. the target distribution\n",
    "plt.xlim(-15,15)\n",
    "plt.legend(['p(x)', 'values of x'])\n",
    "\n",
    "plt.title('Emperical expected value: %s \\n True expected value: %s' %(round(np.mean(samples), 2), round(np.mean(true_exp), 2)), fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the histogram fits the curve but not perfectly. It is pretty jagged and has a lot of error because of which our emperical expected values is not close to the true expected value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: cyan\">\n",
    "with N(1,4) candidate\n",
    "</h3>\n",
    "\n",
    "In the previous case N had to be scaled up (by M) so much because the candidate distribution was centered at 0, whereas the target distribution was centered at 1.\n",
    "\n",
    "So now if we center out candidate at mean=1 we need not scale it up as much and can get a better result.\\\n",
    "AND\\\n",
    "By setting the SD to 4 the tail will flatten out which will bring it above the target distribution easier.\n",
    "\n",
    "This way we can get more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.arange(-30,30,.1)\n",
    "f_vals = [f(x) for x in x_vals]\n",
    "g_vals = g(x_vals, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=1\n",
    "\n",
    "# Plot the two functions\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x_vals, f_vals)\n",
    "plt.plot(x_vals, M*g_vals)\n",
    "plt.title(\"M=%s\"%M, fontsize=15)\n",
    "plt.legend(['f(x)', 'M*g(x)'])\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('Density', fontsize=15)\n",
    "plt.axvline(1, color='b', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=75\n",
    "\n",
    "# Plot the two functions\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x_vals, f_vals)\n",
    "plt.plot(x_vals, M*g_vals)\n",
    "plt.title(\"M=%s\"%M, fontsize=15)\n",
    "plt.legend(['f(x)', 'M*g(x)'])\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('Density', fontsize=15)\n",
    "plt.axvline(1, color='b', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=75\n",
    "\n",
    "# Plot the two functions\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x_vals, f_vals)\n",
    "plt.plot(x_vals, M*g_vals)\n",
    "plt.title(\"M=%s\"%M, fontsize=15)\n",
    "plt.legend(['f(x)', 'M*g(x)'])\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('Density', fontsize=15)\n",
    "plt.axvline(1, color='b', linestyle='--')\n",
    "\n",
    "plt.ylim(0,.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $f(x)$ curve is still not below the $M*g(x)$ curve completely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all accepted samples here\n",
    "samples=[]\n",
    "\n",
    "# try these many candidates\n",
    "N=1000000\n",
    "\n",
    "for _ in  range (N):\n",
    "    # sample a candidate\n",
    "    candidate = np.random.normal(0,3) # 0 is the mean and 3 is the SD\n",
    "\n",
    "    # calculate probability of accepting this candidate\n",
    "    prob_accept = f(candidate) / (M*g(candidate, 0 ,3))\n",
    "\n",
    "    # accept with calculated probability\n",
    "    if np.random.random() < prob_accept:\n",
    "        samples.append(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Samples Collected: %s\"%len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Efficiency: %s\"%round(len(samples) / N, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get more samples than before and the efficiency now is 9%. Much better than the previous 0.7% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(samples, bins=200, density=True)\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('Density', fontsize=15)\n",
    "plt.plot(x_vals, [f/norm_const for f in f_vals], linewidth=2) # [p(x)] i.e. the target distribution\n",
    "plt.xlim(-15,15)\n",
    "plt.legend(['p(x)', 'values of x'])\n",
    "\n",
    "plt.title('Emperical expected value: %s \\n True expected value: %s' %(round(np.mean(samples), 2), round(np.mean(true_exp), 2)), fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The emperical expected value is still the same..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:cyan\">\n",
    "Correlation between drawn samples\n",
    "</h3>\n",
    "\n",
    "There is no correlation between the samples drawn. So the current draw did not depend on the last draw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(samples[:-1], samples[1:], s=1)\n",
    "plt.xlabel('Previous Sample', fontsize=15)\n",
    "plt.ylabel('Current Sample', fontsize=15)\n",
    "\n",
    "corr=round(pearsonr(samples[:-1], samples[1:])[0], 2)\n",
    "plt.title('Correlation: %s'%corr, fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no correlation between the samples drawn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: Yellow\"> \n",
    "Metropolis Algorithm  \n",
    "</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:yellow\">\n",
    "with N(x<sub>prev</sub>, 4) candidate\n",
    "</h3>\n",
    "\n",
    "x<sub>prev</sub> means the centre of the Normal distribution is centred at the last sample with SD of 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all accepted samples here\n",
    "samples=[1]\n",
    "num_accepted=0\n",
    "\n",
    "# try these many candidates\n",
    "N=1000000\n",
    "\n",
    "for _ in  range (N):\n",
    "    # sample a candidate from the normal distribution\n",
    "    candidate = np.random.normal(samples[-1], 4) # samples[-1] is the mean, which is the previous sample and \n",
    "                                                 # where our normal distribution is centered. 4 is the SD.\n",
    "\n",
    "    # calculate probability of accepting this candidate\n",
    "    prob = min(1, f(candidate) / f(samples[-1])) # from the theory of Metropolis Hasting\n",
    "\n",
    "    # accept with calculated probability\n",
    "    if np.random.random() < prob:\n",
    "        samples.append(candidate)\n",
    "        num_accepted += 1\n",
    "\n",
    "    # otherwise repeat current sample again by carrying it forward\n",
    "    else:\n",
    "        samples.append(samples[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_in = 1000\n",
    "retained_samples = samples[burn_in+1:] # starts from 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num Samples Collected: %s\"%len(retained_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Efficiency: %s\"%round(len(retained_samples) / N, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fraction Acceptances: %s\"%np.round((num_accepted / N),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a lot more samples and the efficiency is 99.9%. The best so far. The acceptance rate is aslo around 50% which means 50% of the time we accept the last candidate and 50% of the time we roll over the last candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(retained_samples, bins=200, density=True)\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('Density', fontsize=15)\n",
    "plt.plot(x_vals, [f/norm_const for f in f_vals], linewidth=2) # [p(x)] i.e. the target distribution\n",
    "plt.xlim(-15,15)\n",
    "plt.legend(['p(x)', 'values of x'])\n",
    "\n",
    "plt.title('Emperical expected value: %s \\n True expected value: %s' %(round(np.mean(samples), 2), round(np.mean(true_exp), 2)), fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The emperical expected value is really close to the true expected value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(retained_samples[:-1], retained_samples[1:], s=1)\n",
    "plt.xlabel('Previous Sample', fontsize=15)\n",
    "plt.ylabel('Current Sample', fontsize=15)\n",
    "\n",
    "corr=round(pearsonr(samples[:-1], samples[1:])[0], 2)\n",
    "plt.title('Correlation: %s'%corr, fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation value is much higher now suggesting a relationship between the current and previous samples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
